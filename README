//Christopher Bartz
//cyb01b
//CS4760 S02
//Project 5

syntax: ./oss <arguments>

arguments:
-l testfilename will specify a custom log filename.  Default is log.out.
-q # will set a custom quantum amount for incrementing the OSS clock each cycle.  Default is 100000.
-s # will set the number of concurrent slave processes.  Default is 18. 
-t # will set the total number of real seconds OSS will limit its run.  Default is 2.
-h 	 will print a help message.

Source with revision control is at https://github.com/chrisbartz/cs4760-p5

The project has most requirements working or at least attempted:

Both:
shared memory working
semaphores working

Parent:
OSS forks multiple children at "randomized" times
OSS keeps a simulated clock
OSS allocates shared memory
OSS allocates resources (x20)
OSS keeps track of total CPU time
OSS keeps track of resource requests (unavailable resource requests are put into a queue)
OSS keeps track of resource allocation and release (with some issues - the resource management needs some work as it loses accurate count)
OSS keeps resource "descriptors" in shared memory
OSS DOES NOT have sharable resources - ran out of time with other issues
OSS initializes resources with 10 qty available
OSS forks at random times between 1 and 500 ms
OSS limits the number of child processes to 18 by default
OSS grants resources to child processes as long as there are resources available (otherwise queues the requests)
OSS ATTEMPTED to resolve deadlocks but ran out of time dealing with issues to fully implement
OSS prints a resource map every so many requests
OSS DOES NOT release all resources by terminated children (I thought I wrote a function for this but might have been causing some seg faults)
OSS policy to resolve deadlocks was kill all deadlocked processes
OSS limits run time to 2 real seconds
OSS keeps track of statistics during run time including # requests granted, # resources terminate normally 
OSS DOES NOT keep track of # processes terminated by deadlock detection, how many times deadlock detection was run because that was not completed
OSS sends SIGTERM to all processes on SIGINT
OSS cleanup of shared memory continues to be a problem


Children:
USER requests resources at random times
USER has a bound on when a process can request or release a resource constrained by random selection
USER requests resources through shared memory
USER waits for requested resources to be allocated 
USER sends message when halted/terminated to OSS 
USER checks to see if it should terminate at random times
USER 

Others:
project is available in Github
makefile implemented
README implemented
Simulation ends with execution statistics including average turnaround time, average wait time, idle CPU time

There are a few example commands that work for this project

./oss 
./oss -l thisisastrangelogfilename.log
./oss -q 100001
./oss -s 5
./oss -t 5000
./oss -l notagreatcombo.log -q 1 -s 15 -t 5000

Last minute note:
I still run into resource issues on hoare when forking with a large number of concurrent slave processes (default 18), 
so my suggestion is to run oss with a switch that limits the number of concurrent slave processes to 5 by running the
following command:

./oss -s 5




